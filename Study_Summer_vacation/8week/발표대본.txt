8주차 발표 시작하겠습니다.
이번 강의에선 CNN의 상위 버전 모델들에 대해서 설명하였습니다. 상위 모델들을 알아보기에 앞서 이미지넷 대회에 대해 알아보겠습니다.

이미지넷 대회는 천만장 이상의 이미지, 1000개의 클래스를 갖고 있는 사진들을 분류하는 대회입니다.
여기서 이미지 사이즈는 227 by 227로 구성되어있습니다.
현재 이 대회에서 SOTA 모델은 ViT 모델 중 하나입니다. 
ViT 모델은 Vision in Transformer에서 시작된 시리즈로 비젼에 NLP에서 주로 쓰였던 Transformer 모델을 적용한 모델입니다.
따라서 나중에 computer vision 논문 공부하실 때 Transformer를 적용한 논문 위주로 보시면 최신 논문의 흐름 파악을 할 수 있을 것입니다.

2015년 이전에 이미지넷 경진대회의 우승 모델은 다음과 같습니다. 2012년엔 AlexNet이 우승했습니다. 이 AlexNet은 처음으로 CNN을 베이스로 하여 우승한 모델입니다.
그리고 다음엔 VGG, GoogleNet으로 알려진 Inception 모델, 그리고 최근까지도 많이 사용되고 있는 GoogleNet 모델입니다.
이번 발표에선 이 4개의 아키텍쳐에 대해 살펴보겠습니다.

AlexNet에 대해 소개해드리겠습니다. AlexNet의 아키텍쳐는 보이는 것과 같이 구성되어있고 활성화 함수는 ReLU를 사용하였습니다.
또한, 현재는 쓰이지 않는 Normalization Layer를 사용하였고 Optimizer는 SGD에 모멘텀 0.9로 설정하였습니다.
본 논문의 contribution은 최초로 CNN을 사용하여 우승하였다는 점과 최초로 ReLU 함수를 사용했다는 점입니다. 또한, 앙상블을 이용하여 성능을 항샹시켰습니다.

다음으로 VGGNet입니다. VGG의 아키텍쳐는 VGG종류에 따라 다른데 보통 많이 쓰는 것은 16층과 19층 입니다.
본 논문에서 핵심적으로 봐야할 것은 작은 사이즈의 필터를 사용하여 층을 더 깊게 만든 것입니다. 
이러한 효과로 비선형성이 증가하고 오버피팅은 감소하고 파라미터의 수도 감소하게 하였습니다.
VGG를 기반으로 많은 응용 연구가 진행되었고 나중에 볼 ResNet도 VGG를 기반으로 하고 있습니다.

VGG의 핵심은 작은 필터에 대해 좀 더 자세히 설명드리겠습니다.
그 전까지의 논문은 큰 필터를 사용하여 사이즈를 줄이는 방법을 사용하였습니다. 하지만 VGG에선 작은 필터를 여러번 사용함으로써 사이즈의 손실이 없게 만들었습니다.
그림에서 보이는 바와 같이 7x7 이미지에 3x3 필터를 두번 사용한 것과 5x5 필터를 한 번 사용한 것의 아웃풋은 동일합니다.
그런데 3x3 필터를 2번 사용하게 되면 파라미터 수는 18개가 되고, 5x5 필터를 한 번 사용하게 되면 파라미터 수가 25개가 됩니다.
따라서 큰 필터를 한 번 사용하는 것 보다 작은 필터 여러개를 사용하는 것이 파라미터 수가 적어지기 때문에 작은 필터를 여러번 사용하는 방법을 택합니다.
또한, 앞 장에서 언급했듯이 오버피팅 감소와 비선형성 증가의 효과도 있어서 더욱 높은 성능을 낼 수 있었습니다.

하지만 이런 VGGNet도 단점이 있습니다. 마지막에 Fully Connected Layer를 3개 사용하여 파라미터 수가 급격하게 증가했단 점입니다.
Fully Connected Layer를 완전하게 사용하지 않을 순 없지만 최대한 줄여야지 파라미터 수를 줄일 수 있게 됩니다. googlenet 이후로 부턴 이를 극복합니다.

googleNet은 마지막에 fullyconnected 층을 마지막에 하나만 사용하였습니다. 그리고 아키텍쳐를 보면 옆에 빠지는 부분이 있는데 이는 중간중간에 예측을 실행하여 층이 깊어질 때 weight가 전파되지 않는 문제를 해결하기 위함입니다.
중간중간에 예측을 하고 이를 기반으로 loss 계산하고 다시 여기서 역전파를 함으로써 weight를 input 단 까지 전파를 잘 할 수 있는 아이디어입니다.
따라서 googlenet은 VGG 보다 층을 더 깊게 만들었고, 인셉션 모듈을 사용하였고 더 적은 파라미터를 사용하였습니다.

googlenet의 핵심 아이디어인 인셉션 모듈은 이 그림과 같습니다. 여러 필터 사이즈로 convolution 연산을 하고 이를 합치자라는 게 인셉션 모듈입니다.
하지만 이 방법의 치명적인 단점은 파라미터수가 너무 증가한단 것입니다. input size가 28x28x256이라고 했을 때, 인셉션 모듈을 거치는 파라미터 수를 계산해보면 약 8억개가 나옵니다.

googlenet은 이러한 단점을 극복하기 위해 bottleneck을 사용합니다. bottleneck은 1x1 필터라고 생각하시면 됩니다.
컨볼루션 연산을 하기 전에 1x1 filter를 컨볼루션 연산을 하여 파라미터 수를 줄이는 방법입니다. 실제 계산했을 때 2억개로 줄어드는 것을 볼 수 있습니다.

마지막으로 ResNet입니다. ResNet은 기본적으로 VGG를 베이스로 하며 층을 더 깊게 쌓은 방법입니다. 무려 152층을 쌓았습니다.
본 논문의 contirbution은 skip connection이라는 방법을 제안하고 잔차학습을 최초로 제안한 논문입니다. 이를 통해 층이 깊어졌을 때 생기는 degradation 문제를 해결합니다.

degradation이란 층이 깊어질 수록 성능이 낮아지는 것을 말합니다. overfitting 과는 다른 개념으로 overfitting은 train 성능은 높지만 test 성능은 낮아지는 것이고 degradation은 train,test 성능 둘다 낮은 것을 말합니다.
그래서 이를 해결하기 위해 잔차 학습 개념을 이용합니다.

skip connection에 대해 설명하자면 이는 shortcut connection이라고도 합니다. 이는 한개 이상의 layer를 skip하는 것입니다.
일반적인 layer의 연산과 residual block 즉 잔차 학습을 비교해서 보면 일반 layer연산은 input 값이 convolution 연산을 통과하면서 H(x)라는 값을 구합니다.
그러나 residual block은 기존의 X를 skip connection 하여 잔차 F(x)와 더한 값으로 H(x)를 구합니다. 이를 통해서 역전파 업데이트가 빠르게 되고 input x가 그대로 전달되기 떄문에 degradation 문제가 해결됩니다.

자세한 사항들은 직접 논문을 읽고 보는 것이 괜찮고 특히 resnet 같은 경우는 나동빈씨 유튜브에 자세히 설명되어있으니 그것을 참고해서 보시면 될 것 같습니다.
그리고 resnet code는 설명도 하다가 끊기고 코드 자체가 너무 어렵게 구성되어있어서 이번 설명에서 제외하였고 제가 저번에 보내드린 파이토치 첫걸음 책을 참고하는게 이해가 더 빠르실 것 같습니다.
감사합니다.