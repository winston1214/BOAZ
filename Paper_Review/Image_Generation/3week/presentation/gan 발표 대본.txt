안녕하세요 이번에 발표를 맡게된 김영민이라고 합니다. 오늘 발표는 저와 김지수님 둘이서 함께 발표를 하겠습니다.  
저희가 이번에 발표할 논문은 AI 부분에서 임팩트 팩터가 CVPR 다음으로 높은 NIPS에 개제된 GAN 논문입니다.

발표의 진행순서는 다음과 같습니다. 저는 4번까지만 발표하고 5번부터는 김지수님이 발표를 해주십니다.

먼저 GAN이 왜 생겨났는지 배경에 대해 알아보겠습니다.
기존의 생성모델은 저희가 흔히 아는 GAN 처럼 딥러닝만으로 구현할 수가 없고 Markov chain이나 확률 이론에 기반한 네트워크를 사용하여 별도의 테크닉이 필요하였습니다.
이 논문이 발표될 당시에는 CNN와 같은 깊은 분류 모델의 역전파 방법으로 성능 향상을 이뤘지만 생성 모델은 그러지 못했습니다. 
왜냐하면 기존 생성모델은 확률론적인 모델들을 근사하는데 어려움이 있다는 한계점과 ReLU와 같은 활성화 함수의 장점을 제대로 살리기 어렵다는 한계점이 존재하였기 때문입니다.
따라서 이 논문의 저자는 이러한 한계점을 극복하기 위해 새로운 프레임워크를 제안하는데 이게 바로 GAN 모델입니다.

GAN이란 생성자 generator와 판별자 discriminator의 minmax게임이라고 논문의 저자는 정의합니다. 그리고 이 게임을 오직 multilayer perceptron으로 즉, Neural Network만을 사용해서 이미지 생성을 이뤄냅니다.
비유하자면 위조 지폐 판별 감별사인 Discriminator가 위조 지폐범인 Generator를 잡기 위한 게임이라고 할 수 있습니다. 즉, 위조 지폐범 Generator가 되어 위조 지폐 감별사가 감별을 못할 만큼의 이미지를 생성하는 것이 최종 목표입니다.

다음으로 이 논문의 network인 적대적 네트워크에 대해 설명하겠습니다. 
목적함수는 전에 설명드렸듯이 생성자와 판별자의 minmax 게임을 나타내주는 식입니다. 즉 Generator G를 minize 하고 Descriminator D를 maximize하는 것이 이 목적함수의 목표라고 할 수 있습니다.
다시한번 정리하자면 생성함수 G는 목적함수 V를 낮추려고 노력하고 D는 목적함수 V를 높이기 위해 노력한다는 것으로 정의할 수 있습니다.
이 식을 이해하기 위한 변수에 대해서 설명드리겠습니다. 먼저 우항에 첫번째 식인 p_data x는 원본 데이터의 확률 분포에서 x라는 하나의 값을 sampling 한 것 입니다.
그리고 log D(x)는  sampling한 x를 Descriminator 함수에 넣어주고 이 값에 log를 씌워준 것이고 이 전체를 합친 우변의 첫번째 식은 이 값들의 기대값입니다. 
다음으로 z에 관한 식에 대해 설명드리겠습니다. p_z 는 noise 분포이고 거기서 z라는 sample 값을 추출합니다. 그리고 이를 생성자 G에 넣어주고 이를 판별자 D에 넣어줍니다. 그리고 1-D를 해준 다음에 log를 씌워준 형태입니다.
우선적으로 이 목적함수에서 판별자를 최대화 하는 경우를 우선적으로 살펴보겠습니다. 일단 생성자 G는 고정되어있다고 가정을 합니다. 그러면 G(z)는 하나의 상수로 고정되어 있는 것입니다.
따라서 D(x)=1 일 때, V maximize 조건이 되는 것이고 D(G(z))=0 일 때 V의 최대화 조건이 되는 것입니다.

이어서 생성자를 최소화하는 경우를 살펴보겠습니다. 여기서는 D가 고정값이므로 첫번째 식은 상수취급하게 됩니다. 
그리고 이 식을 풀기 위해선 1-D(G(z))를 최소화 시켜줘야되는데 이를 수행시키기 위해선 D(G(z))=1이 되어서 log0으로 최소화 시킬 수 있게됩니다.

이러한 학습과정을 정리한 flow chart입니다. noise의 분포 샘플 z에서 Generator를 거치고 Fake Image를 뱉으면 Discriminator에선 z가 포함된 식을 학습하게 되고 음의 방향으로 update를 합니다.
그리고 real image를 Discriminator에 넣으면 목적함수를 양의 방향으로 update 하게 됩니다.

다음으로 GAN의 수렴과정에 대해 설명하겠습니다. 이 그림은 시간의 흐름에 따라 즉, 학습이 진행됨에 따라 어떻게 수렴하게 되는지에 대한 그림입니다. 
밑에 보이는 z와 x의 화살표의 의미는 z가 x에 mapping 된다는 의미입니다.
그리고 초록색 선은 생성 분포, 검은색 점선은 실제 이미지의 분포, 그리고 파란색 선은 판별자의 분포입니다.
여기서 검은색 선이 점선인 이유는 실제 이미지는 이산적이어서 점선으로 표현을 한 것입니다. 
그리고 이 그림에서 검은색 점과 초록색 선이 안겹치는 사이 부분이 실제에 없는 이미지지만 실제와 거의 비슷한 새로운 이미지를 의미합니다.
그리고 파란색 선은 점점 한 값으로 수렴하게 되는데 이 값은 2분에 1입니다. 이 값은 P_g와 P_data가 같아질 때의 값인데 이 의미는 생성자가 내보낸 이미지와 실제 이미지와 구분할 수 없다는 것을 의미합니다.

p_g와 P-data가 같아질 때 global optimality가 된다는 것에 대해 설명드리겠습니다. 이를 증명하기 위해 본 논문에선 한가지의 명제를 제시합니다.
사실 이 명제만 성립한다면 딱 봐도 p_g 와 P-data가 같아질 때 1/2가 된다는 것을 알 수 있습니다.
이를 수학적으로 증명한다면 다음의 식과 같습니다. 이는 목적함수를 튜닝하여 증명 과정이 이뤄집니다. 
먼저 목적함수 V에 기대값을 연속 확률 분포의 기대값 공식을 이용하여 적분으로 바꿉니다. 
그리고 z 도메인에서 샘플링된 노이즈 벡터를 G에 넣어서 데이터 x를 만들어 낼 수 있기 때문에 다음의 식처럼 변환이 되는 것입니다.
이렇게 정리된 식은 간단한 공식에 의해 maximize 값을 찾을 수 있게 됩니다. 이 공식에 의해서 a = p_data, b = p_g가 되어서 처음에 설정한 명제가 도출됩니다.

이어서 global opima point가 p_g와 p-data가 같아질때 생성된다는 것을 증명해보겠습니다.우선 별도의 함수 C 값을 정리합니다. 이러한 C는 V의 값을 최대로 만드는 D 에 대한 식입니다. 이 때 G는 고정되어 있다고 가정합니다. 첫번째 식에서 변형되는 과정은 아까 언급했듯이 z 가 x 에 매핑이 되어서 다음과 같이 변형이 되고, 전 슬라이드에서 증명한 식인 D 스타 G x를 식에 대입해줍니다.그리고 이 식에 대해서 약간의 트릭을 쓰는데 각각 log2를 더해주는 것입니다. 그리고 이 식을 쿨백 레이블러 발산 식을 이용하여 변형해줍니다.쿨백 레이블러 발산은 저번주 VAE 논문 리뷰했을 때 설명을 드렸는데, 두개의 분포가 있을 때 그 두개의 분포가 얼마나 차이가 나는지에 대한 것을 수치적으로 표현한 것입니다. 마지막으로 이 식을 젠슨 샤논 다이버전스(Jenson-Shanon-Divergence)로 변형해줍니다. 쿨백 라이블러 발산은 Distance matric으로 활용하긴 어렵기 때문에 젠슨 샤논 다이버전스를 활용하면 Distance matric으로 효과적으로 사용할 수 있습니다. 거리의 개념을 도입하고 생각해보면 JSD를 몰라도 이 식의 최소값은 0인 것을 알 수 있습니다. 그리고 이 최솟값을 가지는 경우는 두 분포가 같을 때 최솟값을 가집니다.

이를 좀 더 자세히 보면 다음과 같습니다. 이 기댓값 식은 앞 슬라이드에서 증명 과정 중 있던 식인데 여기서 p_g와 p_data가 같다는 가정하에 계산하면 기댓값 안에 있는 식이 1이 되서 0 값을 갖게 되고 결국 젠슨 샤논 다이버전스의 값도 0이 되게 됩니다. 그리고 남은 값은 -log(4)가 됩니다. 따라서 정리하자면 Global Minize point는 p_g와 p_data가 같을 때 이고 이 때의 값은 -log(4)가 됩니다.
이어서 지수님께서 설명 이어나가겠습니다.

명제2는 만약 G와 D가 충분한 용량을 가지고 있고, 알고리즘1의 각 단계에서 D가 주어진 G에 대해 최적의 해에 도달하도록 허용하고 Pg가 업데이트 되어 기준을 개선한다면, Pg는 Pdata로 수렴한다
아까 봤던 식을 Pg로 미분하면 앞부분은 상수가 됩니다. 그리고 뒷부분은 Pg에 대해 상수입니다. 따라서 V(G,D)는 Pg에서 convex함수이기 때문에 역전파와 Pg의 적은 업데이트 과정을 통해 Px로 수렴이 가능합니다.

이 실험에서는 MINIST, Toronto Face Database, CIFAR-10 데이터 셋 사용했습니다. Generator nets 에는 rectifier linear activatio과 sigmoid activatio을 혼합해서 사용하고, Discriminator net은 maxout activation을 사용했습니다. 그리고 Dropout은 Discriminator net에 적용하여 훈련하였습니다.
이 논문의 이론적인 프레임워크는 generator의 중간층에서 dropout과 기타 noise를 허용하지 않으나, 실제로는 generator net의 맨 하위 계층에만 입력으로 noise를 사용했습니다.
해당 실험에서 Generator로 생성된 샘플에 Gaussian Parzen window를 맞추고, 해당 분포에 따른 log-likelihood를 알려주는 것에 의해 Pg에 따른 test set data의 확률을 추정한 결과 입니다.
Adversarial nets를 다른 모델들과 비교해 봤을 때 충분히 좋은 성능을 보입니다.

모델에서 나온 샘플을 무작위 추출해 시각화 한 결과입니다.
가장 오른쪽에 노란색 열은 실제 학습 데이터이고, 왼쪽은 GAN을 통해 만들어진 이미지 입니다.
확인한 결과, 학습데이터와 동일한 이미지의 데이터는 찾을 수 없었습니다.
이것은 GAN을 통해 학습된 생성자는 training set을 암기한 것이 아니라 학습 데이터를 바탕으로 그럴싸한 이미지를 생성할 수 있는 능력을 가지고 있음을 보여줍니다.

이러한 새로운 framework는 이전 모델에 대해서 장단점이 있습니다.
먼저 단점은 Pg(x)의 명시적인 표현이 없으며, D가 훈련 중 G와 동기화가 잘 되어야한다는 것입니다. G는 D의 업데이트 없이 너무 많이 학습되면 안됩니다.
장점은 주로 계산에 관련된 부분인데, Markov chain이 필요 없고, gradients를 얻기 위해 역전파만 사용될 뿐, 학습 중에 추론이 필요 없다는 것입니다. 또한, 다양한 기능을 모델에 통합할 수 있습니다.

결론에 대해 말씀드리겠습니다.
1. Conditional generative model P(𝑥|𝑐)는 c를 G와 D에 모두 입력함으로써 얻어질 수 있습니다.
2. 학습된 근사 추론은 x가 주어진 z를 예측하도록 보조 네트워크를 학습하여 수행할 수 있습니다. 이것은 generator net이 학습을 마친 후에 추론 network가 고정된 generator net에 대해 훈련될 수 있다는 이점이 있습니다.
3. 모든 조건부 P(𝑥_𝑠 |𝑥_$)를 근사 모델링 할 수 있습니다. 여기서 S는 매개 변수를 공유하는 조건부 모델의 계열을 훈련하여 x 인덱스의 하위 집합입니다.
4. 반-감독 학습은 discriminator나 추론 network의 특징은 제한된 레이블이 있는 데이터를 사용할 수 있을 때, classifiers의 성능을 향상시킬 수 있습니다.
5. 효율성 향상은 G와 D를 조정하는 더 나은 방법을 세우거나 훈련 중에 sample z에 대한 더 나은 분포를 결정함으로써 학습을 크게 가속화 할 수 있습니다.
해당 논문은 adversarial modeling framework의 가능성을 보여주며, 이러한 연구 방향이 유효할 수 있다는 것을 증명하였습니다.












