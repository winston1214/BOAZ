{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 모델 실습\n",
    "## 핸드폰 가격 예측 모델 만들기\n",
    "*데이터 : https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv\n",
    "\n",
    "*코드 참고 : https://chancoding.tistory.com/67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"   \")  # 본인 파일 주소 넣으시면 됩니다.\n",
    "test=pd.read_csv(r\"   \")   # 본인 파일 주소 넣으시면 됩니다.\n",
    "\n",
    "#데이터의 기본 구조 확인\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "#결측값(missing value)는 분석 오류를 발생시키거나 왜곡시킬 위험이 있습니다.\n",
    "#따라서 분석할 DataFrame을 생성하고나면 결측값 여부를 확인합니다.\n",
    "\n",
    "df.isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 프레임 기본 상태 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가격을 나타내는 target value 확인 \n",
    "#우리는 \"핸드폰 가격\"을 예측하려고 합니다. \n",
    "#해당 데이터는 0, 1, 2, 3 네 개의 class를 가진 카테고리형 데이터입니다.\n",
    "\n",
    "df['price_range'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM 모델 생성   (ppt 20p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 와 target 분리\n",
    "\n",
    "# target은 우리의 target 데이터인 \"price_range\"\n",
    "yt=np.array(df['price_range']) \n",
    "\n",
    "# feature는 target 데이터를 뺀 나머지 데이터 전부\n",
    "xt=df.drop(['price_range'], axis=1) \n",
    "xt=np.array(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler : 각 Feature의 값을 일정한 범위 또는 규칙에 따르게 하기 위해서 스케일링을 사용\n",
    "# MinMaxScaler : 최소 0 ~ 최대 1 사이로 feature의 값을 변환\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xt=scaler.fit_transform(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 데이터 split\n",
    "# 훈련용 데이터인 'train.csv' 의 데이터 값들을 다시 훈련과 검증용 데이터로 split 해야함\n",
    "# x_train :  data 값\n",
    "# y_train : target 값 (price_range)\n",
    "# x_valid : data 값\n",
    "# y_valid : target 값 (price_range)\n",
    "# 훈련용 : 검증용 데이터를 8 : 2 로 분리  --> test_size = 0.2\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(xt, yt, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. linear kernel  SVC를 통해 적절한 C 찾기  (ppt 22p)\n",
    "\n",
    "#### C\n",
    "- C 는 SVM의 기본 파라미터\n",
    "- 슬랙 변수의 가중치\n",
    "- 분류를 하는데 오차를 허용하는 범위인 마진 값을 조정함\n",
    "- C 값이 커질수록 오분류 허용 X\n",
    "- C 값이 작아지면 margin 폭 좁아짐.\n",
    "- C 값이 커지면 margin 폭 넓어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear 커널 SVC\n",
    "\n",
    "scores = []\n",
    "for thisC in [*range(1,50)]:\n",
    "    svc = SVC(kernel='linear', C = thisC)  #linear kernel SVC의 파라미터 : kernel , C\n",
    "    model = svc.fit(xtrain, ytrain)\n",
    "    scoreTrain = model.score(xtrain, ytrain)\n",
    "    scoreTest = model.score(xtest,ytest)\n",
    "    print(\"Linear SVM : C :{}, training score:{:2f}, test score:{:2f}\".format(thisC, scoreTrain, scoreTest))\n",
    "scores.append([scoreTrain, scoreTest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. rbf kernel 사용한 SVC를 통해 적절한 C 와 gamma 찾기  (ppt 23p)\n",
    "\n",
    "#### C\n",
    "- C 는 SVM의 기본 파라미터\n",
    "- 슬랙 변수의 가중치\n",
    "- 분류를 하는데 오차를 허용하는 범위인 마진 값을 조정함\n",
    "- C 값이 커질수록 오분류 허용 X\n",
    "- C 값이 작아지면 margin 폭 좁아짐.\n",
    "- C 값이 커지면 margin 폭 넓어짐\n",
    "\n",
    "#### gamma\n",
    "- 가우시안 함수의 표준편차와 관련있는 매개변수\n",
    "- gamma는 RBF 커널에서 하나의 데이터 샘플이 영향력을 행사하는 거리를 나타냄\n",
    "- gamma가 크면 데이터 포인터들이 영향력을 행사하는 거리가 짧아짐\n",
    "- gamma가 작으면 영향력을 행사하는 거리가 커짐\n",
    "- gamma가 커질수록 곡률 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF 커널 SVM\n",
    "for thisGamma in [.1, .25, .5, 1] :  # gamma 값을 [ 0.1 , 0.25 , 0.5 , 1 ]로 다양하게 지정\n",
    "    for thisC in [ 1, 5, 10, 20, 40, 100] : # C 값을 [ 1, 5, 10, 20, 40, 100 ] 으로 다양하게 지정\n",
    "        model2 = SVC(kernel=\"rbf\", C=thisC, gamma = thisGamma).fit(xtrain, ytrain) #linear kernel SVC의 파라미터 : kernel , C , gamma\n",
    "        m2train = model2.score(xtrain, ytrain)\n",
    "        m2test = model2.score(xtest, ytest)\n",
    "        print(\"RBF SVM : C:{}, gamma:{},training score:{:2f},test score:{:2f} \\n\".format(thisC, thisGamma, m2train, m2test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 하지만 c 와 gamma를 어느 세월에 다 찾을 수 있을까?\n",
    "\n",
    "### 3-3. GridSearchCV를 사용 (ppt 25p)\n",
    "\n",
    "최적의 파라미터와 그 때의 score 값을 한 번에 찾아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param={'C':[1,5,10,20,40,100],\n",
    "      'gamma':[.1, .25, .5, 1]}\n",
    "GS=GridSearchCV(SVC(kernel='rbf'),param, cv=5)\n",
    "GS.fit(xtrain, ytrain)\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 예측\n",
    "\n",
    "test에 적용 후 최종 예측 값 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(['id'],axis=1)\n",
    "test.head()\n",
    "testmat=np.array(test)\n",
    "test=scaler.fit_transform(test)\n",
    "#test(DF -> array)\n",
    "model=SVC(kernel='rbf', C=5, gamma=.1).fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(test)\n",
    "pred=pd.DataFrame(prediction)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*수고하셨습니다*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
