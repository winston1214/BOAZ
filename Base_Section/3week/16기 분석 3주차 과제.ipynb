{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxQ2YTAv4tB-"
   },
   "source": [
    "## 회귀\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음과 같은 종속 변수 Y와 두 개의 독립 변수 X1,X2를 갖고 있는 데이터가 있습니다. Regressing Tree를 통해 Y를 예측하고자 할 때, 처음으로 분할 되는 변수 및 분할 point를 찾아 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Image(\"C:/Users/kdh2/Desktop/세션강의자료/2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Kj9OhTr5WXX"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "#보스톤 데이터셋은 범죄율, 강의 인접 유무, 세금 등 13개의 변수를 가지고 있으며, 주택 가격을 라벨 데이터로 가지고 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <특징 데이터>\n",
    "CRIM: 범죄율<br>\n",
    "INDUS: 비소매상업지역 면적 비율<br>\n",
    "NOX: 일산화질소 농도<br>\n",
    "RM: 주택당 방 수<br>\n",
    "LSTAT: 인구 중 하위 계층 비율<br>\n",
    "B: 인구 중 흑인 비율<br>\n",
    "PTRATIO: 학생/교사 비율<br>\n",
    "ZN: 25,000 평방피트를 초과 거주지역 비율<br>\n",
    "CHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0<br>\n",
    "AGE: 1940년 이전에 건축된 주택의 비율<br>\n",
    "RAD: 방사형 고속도로까지의 거리<br>\n",
    "DIS: 직업센터의 거리<br>\n",
    "TAX: 재산세율<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston.data\n",
    "label = boston.target\n",
    "columns = boston.feature_names\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data, columns = columns)\n",
    "label=pd.DataFrame(label,columns=['label'])\n",
    "\n",
    "data.head()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#변수를 split 해주세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor와 DecisionTreeClassifier를 쓰는 상황을 구분하여 작성 해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['RM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) x 변수로 'RM' 변수를, y 변수는 주택 가격으로 하여 회귀트리모델을 돌려주세요.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) 트리의 max_depth는 5로 지정해주세요\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg=DecisionTreeRegressor(max_depth=5)\n",
    "#fit()을 이용하여 모델 학습\n",
    "\n",
    "#예측값=\n",
    "pred="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) R<sup>2</sup> 으로 회귀 모델이 데이터를 잘 표현하는지 확인해주세요.\n",
    "(R<sup>2</sup>값이 1에 가까울수록 회귀 모델이 데이터를 잘 표현한다는 것을 의미합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x = np.linspace(np.min(X_test['RM']), np.max(X_test['RM']), 10)\n",
    "line_y = tree_reg.predict(line_x.reshape((-1, 1)))\n",
    "\n",
    "plt.scatter(X_test['RM'].values.reshape((-1, 1)), y_test, c = 'black')\n",
    "plt.plot(line_x, line_y, c = 'red')\n",
    "plt.legend(['Regression line', 'Test data sample'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 하나로는 R<sup>2</sup>값이 높지 않은 것을 확인하였습니다.\n",
    "#### 3) 13개의 변수를 모두 사용해 결정 트리 회귀 모델을 사용해 보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#파라미터 조정 자유입니다. \n",
    "tree_reg2=DecisionTreeRegressor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adult_path = join('C:\\\\Users\\\\kdh2\\\\보아즈 과제', 'adult_data.csv')\n",
    "column_path = join('C:\\\\Users\\\\kdh2\\\\보아즈 과제', 'adult_names.txt')\n",
    "adult_columns = list()\n",
    "for l in open(column_path):\n",
    "    adult_columns = l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(adult_path, names = adult_columns)\n",
    "data['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = data['income']\n",
    "del data['income']\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas get_dummies 함수를 사용해 범주형 변수를 One-Hot Encoding하고, 라벨 데이터를 0,1 로 변경\n",
    "data = pd.get_dummies(data)\n",
    "label = label.map(lambda x : 0 if x =='>50K' else 1)\n",
    "data\n",
    "label.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (Train, Valid), Test 분할\n",
    "X_train, X_test, y_train,y_test=train_test_split(data,label,test_size=0.2,random_state=785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid 분할\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=0.2,random_state=785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤 포레스트로 모델을 학습시켜 주세요.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Valid 데이터로 검증\n",
    "\n",
    "\n",
    "print(\"랜덤 포레스트 검증 데이터 정확도 : {:.2f}%\".format(accuracy_score(y_valid,y_pred)*100))\n",
    "\n",
    "# Test 데이터로 모델 평가\n",
    "print(\"랜덤 포레스트 테스트 데이터 정확도 : {:.2f}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "간단히 GridSearchCV 함수를 사용해 랜덤 포레스트의 n_estimator, max_depth 파라미터 중 가장 좋은 파라미터 조합을 찾아보겠습니다.<br>\n",
    "GridSearchCV 함수는 Sklearn의 model_selection 패키지에 있습니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100], \n",
    "    #n_estimators를 여러개로 주면 너무 느려서 한개로 했습니다. 여러개로 돌려보시고 더 높은 성능이 나오면 그것으로 해도 무방합니다\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "\n",
    "#위의 리스트 값말고 다른값들로 돌려보았을 때 괜찮은 값 있으면 변경하셔도 됩니다.\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "\n",
    "grid_cv=GridSearchCV()\n",
    "grid_cv.fit()\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 위에서 나온 최적 하이퍼 파라미터로 모델을 학습시켜 주세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 개별 feature들의 중요도를 시각화해주세요.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50개의 변수에 대한 200개의 관측치를 갖는 데이터 셋을 갖고 있다고 가정합시다. 랜덤 포레스트를 돌려 importance plot을 그리고 나서, 그 결과를 바탕으로 상위 10개의 변수를 이용하여 선형 회귀를 fit했다고 가정해봅시다. 이때 회귀 모델이 랜덤 포레스트에 비해 성능이 훨씬 안 좋았습니다. 이러한 결과가 도출된 이유(가능성)에 대해서 두 가지 이상 제시해주세요.\n",
    "- \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#원하는 모델 3개를 골라 VotingClassifier을 돌려주세요.\n",
    "#저는 성능 상관없이 모델을 가져왔는데 부담없이 원하시는 모델을 돌려주시면 됩니다ㅎㅎ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "models=[('lgbm',LGBMClassifier()),\n",
    "       ('xgbm',XGBClassifier()),\n",
    "       ('svc',SVC(probability=True))]\n",
    "\n",
    "soft_vote=VotingClassifier(models, voting='soft')\n",
    "vote_cv=cross_validate(soft_vote,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_vote.fit(X_train,y_train)\n",
    "vote_pred=soft_vote.predict(X_test)\n",
    "print(accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수고하셨습니다:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_03) Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
